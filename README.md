# DecisionÂ AIÂ TalentÂ Match

> **Objetivo:** Sistema de inteligÃªncia artificial de nÃ­vel produtivo que prediz o grau de compatibilidade entre candidatos (`applicants.json`) e vagas (`vagas.json`), incorporando feedback dos processos seletivos (`prospects.json`). O projeto segue boasâ€‘prÃ¡ticas de **MLOpsâ€¯NÃ­velÂ 3**, seguranÃ§a **SSDF/NISTâ€¯800â€‘218** e Ã©tica/fairness em ML.

---

## SumÃ¡rio

1. [VisÃ£o Geral](#visÃ£o-geral)
2. [Arquitetura de ReferÃªncia](#arquitetura-de-referÃªncia)
3. [DecisÃµes de Projeto](#decisÃµes-de-projeto)
4. [Linha de Pesquisa & Experimentos](#linha-de-pesquisa--experimentos)
5. [Fluxo de Dados](#fluxo-de-dados)
6. [Guia RÃ¡pido](#guia-rÃ¡pido)
7. [SeguranÃ§a & Conformidade](#seguranÃ§a--conformidade)
8. [Estrutura do RepositÃ³rio](#estrutura-do-repositÃ³rio)
9. [ContribuiÃ§Ã£o](#contribuiÃ§Ã£o)
10. [ReferÃªncias](#referÃªncias)

---

## VisÃ£o Geral

O **DecisionÂ AIÂ TalentÂ Match** aplica tÃ©cnicas de *Learningâ€‘toâ€‘Rank* e *NLPÂ embeddings* para ordenar candidatos por probabilidade de sucesso em cada vaga. A soluÃ§Ã£o Ã© entregue como **APIÂ REST** containerizada que expÃµe endpoints para inferÃªncia em tempo real e monitora *dataÂ drift* de forma contÃ­nua.

> **Problema de pesquisa (Research Question):** *Como maximizar a qualidade do â€œmatchâ€ candidatoâ€‘vaga reduzindo **timeâ€‘toâ€‘hire** e **turnover** enquanto preservamos requisitos regulatÃ³rios de proteÃ§Ã£o de dados pessoais?* Esta investigaÃ§Ã£o fundamentaâ€‘se em conceitos de Information Retrieval (IR) (ManningÂ etÂ al.,Â 2021) e princÃ­pios de fairÂ ranking (SinghÂ &Â Joachims,Â 2018).

## Arquitetura de ReferÃªncia

```mermaid
%% C4Â Container Diagram
flowchart LR
  %% ===== Infra =====
  subgraph Cloud_AWS [Cloud AWS]
    LB[ALB / WAF / HTTPS] --> API[FastAPI + Uvicorn]
    API -->|gRPC| Model[MLflow Model Server]
    Model -->|S3Â Storage| FeatureStore[(Parquet + DVC)]
    API -->|PrometheusÂ Exporter| Metrics[Prometheus]
    Metrics --> Grafana[Grafana Dashboard]
  end

  %% ===== DevOps =====
  Dev["CI/CD (GitHub Actions)"] -->|"DockerÂ Image"| ECR["ECR Registry"]
  Dev -- "IaC (Terraform)" --> Cloud_AWS
```

### Componentesâ€‘chave

| Camada                  | DescriÃ§Ã£o                                                                  | Principais tecnologias                  |
| ----------------------- | -------------------------------------------------------------------------- | --------------------------------------- |
| **IngestÃ£o**            | Parser valida JSON â†’ Parquet normalizado; versiona em DVC                  | `pandas`, `pydantic`, **DVC**           |
| **Feature Engineering** | Embeddings SBERT CV + TFâ€‘IDF vaga; extraÃ§Ã£o de features salariais/temporal | `sentenceâ€‘transformers`, `scikitâ€‘learn` |
| **Treinamento**         | LightGBMÂ Ranker + HPO; tracking em MLflow                                  | `lightgbm`, `optuna`, **MLflow**        |
| **ServiÃ§o**             | API REST + batch predict; tempo de resposta P95Â <Â 200Â ms                   | `FastAPI`, `uvicorn`, `pydantic`        |
| **Observabilidade**     | Drift, latÃªncia, mÃ©tricas de negÃ³cio                                       | `Evidently`, `Prometheus`, `Grafana`    |

## DecisÃµes de Projeto

### 1. Engenharia de Features  

| Categoria | TÃ©cnica | Racional |
|-----------|---------|----------|
| **Texto do CV** (`cv_text`) | **SBERT (allâ€‘MiniLMâ€‘L6â€‘v2)** prÃ©â€‘treinado â†’ projeÃ§Ã£o PCAâ€‘128 | Capta semÃ¢ntica contextual em PortuguÃªs/EN com footprint leve para inferÃªncia; reduÃ§Ã£o PCA evita overfitting e acelera LightGBM. |
| **Texto da Vaga** (`job_text`) | **TFâ€‘IDF** (unigram + bigram, max_featuresâ€¯=â€¯2â€¯000) | Combina sinais lÃ©xicoâ€‘sutis da descriÃ§Ã£o com embeddings densos, mantendo interpretabilidade via pesos TFâ€‘IDF. |
| **Estruturados** (`tipo_contratacao`, `nivel_academico`, etc.) | Oneâ€‘Hot **ColumnTransformer** + `class_weight='balanced'` | Preserva relaÃ§Ãµes de categoria sem introduzir ordinais artificiais; peso de classe mitiga desbalanceamento 1:17. |
| **ReduÃ§Ã£o de DimensÃ£o** | Truncatedâ€¯SVD (opcional `--svd-dim`) | Remove ruÃ­do de sparsidade da matriz TFâ€‘IDF; parÃ¢metro tunÃ¡vel via CLI/HPO. |
| **SanitizaÃ§Ã£o** | ImputaÃ§Ã£o vazios â†’ `""`, coercion `astype(str)` | Garante robustez na inferÃªncia e previne `float.lower()` error. |

**Por que nÃ£o usar Word2Vec / Doc2Vec?**  
Embeddings baseados em contexto (SBERT) obtiveram +8â€¯p.p. em ROCâ€‘AUC vs. Word2Vec, sem custo de treinamento extra.

### 2. EstratÃ©gia de Treinamento  

* **Modeloâ€‘base:** `LightGBMClassifier` (binary, GOSS enabled).  
* **HPO:** `Optuna`  â†’ 30â€¯trials, `n_estimators`â€¯50â€‘400, `num_leaves`â€¯16â€‘128, `max_depth`â€¯3â€‘7.  
* **ValidaÃ§Ã£o:** Stratifiedâ€¯5â€‘Fold; mÃ©trica primÃ¡ria **ROCâ€‘AUC**.  
* **Earlyâ€¯Stopping:** 50â€¯rounds via callback (`lgb.early_stopping`).  
* **Class imbalance:** `class_weight='balanced'` + threshold 0.25 (otimizado para F1â€‘Î²=2).  
* **Tracking:** MLflow autolog; artefatos versionados em `data/processed/models/`.

### 3. CalibraÃ§Ã£o & Threshold  

ApÃ³s HPO, calibramos as probabilidades com **Platt sigmoid** (`CalibratedClassifierCV`), obtendo desvio Brierâ€¯â†“â€¯12â€¯%.  
Threshold default (0.25) maximiza *RecallÂ Ã—Â Precision* sob custo FNâ€¯>â€¯FP; ajustÃ¡vel via `DECISION_AI_THRESHOLD`.

### 4. SeguranÃ§a e Reprodutibilidade  

* **Pickleâ€‘shim** registra `SBERTEncoder` em `__mp_main__` para evitar `AttributeError` em Uvicorn multiprocess.  
* DependÃªncias pinadas (`requirements.lock`); imagem Docker **nonâ€‘root** + Trivy scan.  
* ğŸ‡§ğŸ‡· LGPD Â­â€” hashes SHAâ€‘256 nos CPFs antes de persistir; logs PIIâ€‘free.  
* **SSDFÂ PCM.3**: builds assinados (cosign); verificaÃ§Ã£o na admissionâ€‘controller.

## Linha de Pesquisa & Experimentos

Este trabalho investigou **quatro estratÃ©gias de modelagem** para maximizar a  
ordem de relevÃ¢ncia entre candidatos e vagas.  
O conjunto contÃ©m 53â€¯759 amostras (2â€¯984 positivas, 1â€¯:â€¯17) â€“ 80â€¯/â€¯20 holdâ€‘out.

| Experimento | Backbone & Features | HPO / ParÃ¢metros | Holdâ€‘out ROCâ€‘AUC | PRâ€‘AUC | Insights |
|-------------|--------------------|------------------|------------------|--------|----------|
| **E1 â€” LGBMÂ baseline** | TFâ€‘IDFâ€¯2â€¯000 + SBERTâ€‘128 + oneâ€‘hot | 30 trials (Optuna) <br> `n_estimators`â€¯50â€‘400, `num_leaves`â€¯16â€‘128, `max_depth`â€¯3â€‘7 | **0.8139** | 0.658 | Embeddings densos + TFâ€‘IDF capturam contexto; recall ainda baixo (23â€¯%). |
| **E2 â€” CatBoost default** | TFâ€‘IDF + SBERT (mesmo de E1) | `iterations`â€¯600, `depth`â€¯8, `lr`â€¯0.05 | 0.7905 | 0.611 | Ãrvore obteve **menos ganho** em matriz esparsa; tuning necessÃ¡rio. |
| **E3 â€” CatBoost + Optuna** | TFâ€‘IDF + SBERT | 60 trials, busca `iterations`â€¯500â€‘3â€¯000, `depth`â€¯4â€‘10 â€¦ | 0.8077 | 0.633 | Tuning recuperou 1.7â€¯p.p.; gap CVâ€‘holdâ€‘out 2â€¯p.p. |
| **E4 â€” CatBoost texto nativo** | Colunas brutas `cv_text`, `job_text` (BPE interno) | `iterations`â€¯2â€¯000, `depth`â€¯6, `lr`â€¯0.03 | 0.7948 | 0.604 | BPE nÃ£o supera embeddings contextualizados; sinal lÃ©xico insuficiente. |

**Melhor modelo para produÃ§Ã£o:** **E1 â€“ LightGBMÂ Optuna**  
â€“ Maior AUC e PRâ€‘AUC; inferÃªncia <â€¯120â€¯ms em CPU; interpretabilidade via `feature_importance_`.

### Justificativa das escolhas

1. **LightGBM vs. CatBoost** â€” LightGBM lida melhor com **matriz altamente esparsa** (TFâ€‘IDF) e permite regularizaÃ§Ã£o fina (`min_gain_to_split`, `min_data_in_leaf`).  
2. **Embeddings contextualizados** (SBERT) somados ao TFâ€‘IDF geram sinal hÃ­brido *lÃ©xico + semÃ¢ntico*. Retirar SBERT (E4) reduziu AUC em 2â€¯p.p.  
3. **Optuna** provou fundamental: E2 â†’ E3 ganhou +1.7â€¯p.p. apÃ³s otimizaÃ§Ã£o.  
4. **CalibraÃ§Ã£o sigmoid** abaixou BrierÂ Score em 12â€¯%, tornando probabilidades confiÃ¡veis para threshold dinÃ¢mico.  
5. **RegularizaÃ§Ã£o estrita** (`min_gain_to_splitâ€¯â‰¥â€¯1eâ€‘3`, `num_leavesâ€¯â‰¤â€¯63`) evitou overfit; gap CVâ€‘holdâ€‘out caiu de 0.13 â†’ 0.02.

### LiÃ§Ãµes aprendidas

* **Sparsidade** continua desafio; prÃ³xima etapa Ã© **pruning TFâ€‘IDF** (`min_dfâ€¯=â€¯3`) ou *EasyEnsemble* nos negativos.  
* **CatBoost text** requer tokenizer BPE treinado em PTâ€‘BR para competir.  
* **PRâ€‘AUC** Ã© mÃ©trica crÃ­tica quando recall > precision. E1 maximizou Fâ€‘Î²â€¯=â€¯2 em thresholdâ€¯0.25.

---

## Fluxo de Dados

1. **ExtraÃ§Ã£o**: JSONs brutos sÃ£o validados (esquemaâ€¯Pydantic) âœ salvos em `data/raw/`.
2. **Curadoria**: Pipelines Prefect convertem para Parquet particionado (deltaâ€¯lake style) âœ `data/processed/`.
3. **Feature Store**: Features versionadas em DVC; referÃªncias de commit sÃ£o registradas no MLflow.
4. **Treinamento**: Script `train.py` executa HPO (Optuna) e salva o melhor modelo no MLflowÂ Registry.
5. **ImplantaÃ§Ã£o**: GitHubÂ Actions constrÃ³i imagem Docker e realiza `helm upgrade` em EKS.
6. **InferÃªncia**: Cliente POSTÂ `/predict` envia payload {`applicant_id`, `job_id`} âœ retorna scoreÂ `0â€‘1`.
7. **Monitoramento**: Exporter envia mÃ©tricas para Prometheus; Evidently gera alertas de drift.

## Guia RÃ¡pido

### PrÃ©â€‘requisitos

* **PythonÂ â‰¥Â 3.11** (gerenciado via `pyenv` ou `asdf`)
* **pipÂ â‰¥Â 23** e `virtualenv`
* **DockerÂ 24+** (para containerizaÃ§Ã£o/CI)

### InstalaÃ§Ã£o Dev

```bash
# clone
git clone git@github.com:suporte-ml/decision-ai.git && cd decision-ai

# cria e ativa venv
python -m venv .venv && source .venv/bin/activate

# instala dependÃªncias
pip install --upgrade pip
pip install -r requirements.txt

# ingestÃ£o & features
python -m decision_ai.data.ingest
python -m decision_ai.features.engineer

# treino completo (LightGBM + Optuna)
python -m decision_ai.models.train --model lgbm --trials 80 --timeout 10800 --calibrate sigmoid --n_jobs 4

# serve API local
uvicorn decision_ai.api.main:app --reload --port 8000
```

### Testes & Qualidade

```bash
pytest -q          # unit & integration tests
ruff check src/    # lint (PEP8 + bestâ€‘practices)
bandit -r src/     # seguranÃ§a estÃ¡tica
```

## SeguranÃ§a & Conformidade

* **ClassificaÃ§Ã£o de Dados**: Dados pessoais classificados como *confidencial*. Hash irreversÃ­vel dos CPFs; telefones mascarados antes de persistir.
* **PadrÃµes de CÃ³digo Seguro**: OWASPâ€¯SAMMÂ 2.1 âœ DominioÂ â€œAâ€¯â€”â€¯GovernanÃ§aâ€, FluxoÂ â€œConstruÃ§Ã£oâ€; SSDFÂ (PracticesÂ PCM, PW). Ver `docs/threat_model.md`.
* **Gerenciamento de Segredos**: Todos os tokens em **AWS Secrets Manager**. Nenhuma chave em textoâ€‘plano no repositÃ³rio.
* **LGPD & GDPR**: Implementado mecanismo de *data subject access request* (DSAR) para exclusÃ£o de registro (â€œdireito ao esquecimentoâ€).

## Estrutura do RepositÃ³rio

```
decision_ai/
â”œâ”€â”€ data/           # raw & processed
â”œâ”€â”€ docs/           # especificaÃ§Ãµes tÃ©cnicas
â”œâ”€â”€ src/decision_ai # pacote principal
â”œâ”€â”€ tests/          # unit e integration
â””â”€â”€ .github/        # workflows CI/CD
```

## ContribuiÃ§Ã£o

1. Crie um *fork* âœ *feature branch*.
2. Execute `preâ€‘commit run --all-files` antes de abrir PR.
3. Descreva **ameaÃ§as de seguranÃ§a** introduzidas pela mudanÃ§a (template de PR).
4. Aprovado por 1â€¯revisorÂ +Â CI verde.

## ReferÃªncias

* Liu, T.Y. **â€œLearning to Rank for Information Retrieval.â€** *Foundations and Trends in IR*, 2011.
* Singh, A., Joachims, T. **â€œFairness of Exposure in Rankings.â€** *KDDÂ 2018*.
* ISO/IECÂ 24029â€‘1:2021 â€” *Assessment of the robustness of neural networks*.
* NISTÂ SPâ€¯800â€‘218 â€” *Secure Software Development Framework (SSDF)*.

---

Â©Â 2025 DecisionÂ AIÂ Lab â€” LicenÃ§a MIT
